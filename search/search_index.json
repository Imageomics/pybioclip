{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pybioclip","text":"<p>Command line tool and python package to simplify the use of BioCLIP.</p> <p>Key features include:</p> <ul> <li>Taxonomic label prediction for images across ranks in the Linnaean hierarchy (tunable from kingdom to species).</li> <li>Custom label predictions from user-supplied classification categories.</li> <li>Image embedding generation in a text-aligned feature space.</li> <li>Batch image processing with performance optimizations.</li> <li>Containers provided to simplfy use in computational pipelines.</li> </ul> <p>No particular coding knowledge of ML or computer vision is required to use pybioclip.</p>"},{"location":"#installation","title":"Installation","text":"<p>Requires python that is compatible with PyTorch.</p> <p><pre><code>pip install pybioclip\n</code></pre> If you have any issues with installation, please first upgrade pip by running <code>pip install --upgrade pip</code>.</p>"},{"location":"#tutorials","title":"Tutorials","text":"<p>Command Line Tutorial Python Tutorial</p>"},{"location":"acknowledgments/","title":"Acknowledgments","text":"<p>The Imageomics Institute is supported by the National Science Foundation under Award No. 2118240 \"HDR Institute: Imageomics: A New Frontier of Biological Information Powered by Knowledge-Guided Machine Learning.\" Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p> <p>The prediction code in pybioclip is based on work by @samuelstevens in bioclip-demo.</p>"},{"location":"apptainer/","title":"Apptainer Container","text":"<p>Apptainer/Singularity images for pybioclip are provided at ghcr.io/Imageomics/pybioclip-sif registry.</p> <p>NOTE: It is also possible to download the pybioclip docker container and convert that into a singularity container, but that process can take quite a while.</p>"},{"location":"apptainer/#tutorial","title":"Tutorial","text":""},{"location":"apptainer/#download-example-images","title":"Download example images","text":"<p>Download two images from the bioclip-demo.</p> <pre><code>wget https://huggingface.co/spaces/imageomics/bioclip-demo/resolve/main/examples/Ursus-arctos.jpeg\nwget https://huggingface.co/spaces/imageomics/bioclip-demo/resolve/main/examples/Felis-catus.jpeg\n</code></pre>"},{"location":"apptainer/#download-a-pybioclip-container","title":"Download a pybioclip container","text":"<p><pre><code>apptainer pull oras://ghcr.io/imageomics/pybioclip-sif:1.0.0\n</code></pre> The above command will create a <code>pybioclip_1.0.0.sif</code> container image file.</p>"},{"location":"apptainer/#create-predictions-using-a-cpu","title":"Create predictions using a CPU","text":"<pre><code>./pybioclip_sif_1.0.0.sif bioclip predict Ursus-arctos.jpeg Felis-catus.jpeg\n</code></pre>"},{"location":"apptainer/#create-predictions-using-a-gpu","title":"Create predictions using a GPU","text":"<p>This step requires a cuda GPU.</p> <pre><code>apptainer exec -nv ./pybioclip_sif_1.0.0.sif bioclip predict --device cuda Ursus-arctos.jpeg Felis-catus.jpeg\n</code></pre>"},{"location":"apptainer/#create-predictions-using-a-gpu-via-a-slurm-job","title":"Create predictions using a GPU via a Slurm Job","text":"<p>This step requires being on a Slurm cluster.</p> <p>Create a Slurm sbatch script named <code>bioclip.sh</code> with the following content: <pre><code>#!/bin/bash\n#SBATCH --nodes=1\n#SBATCH --time=00:10:00\n#SBATCH --gpus-per-node=1\napptainer exec --nv ./pybioclip_sif_1.0.0.sif bioclip predict --device cuda $*\n</code></pre> Run the slurm job filling in your Slurm account: <pre><code>sbatch --account &lt;SLURMACCT&gt; bioclip.sh Ursus-arctos.jpeg Felis-catus.jpeg\n</code></pre></p>"},{"location":"command-line-help/","title":"Command Line Help","text":""},{"location":"command-line-help/#bioclip-predict","title":"bioclip predict","text":"<p>Use BioCLIP to generate predictions for image files. <pre><code>usage: bioclip predict [-h] [--format {table,csv}] [--output OUTPUT]\n                       [--rank {kingdom,phylum,class,order,family,genus,species} |\n                        --cls CLS | --bins BINS | --subset SUBSET] [--k K]\n                       [--device DEVICE] [--model MODEL] [--pretrained PRETRAINED]\n                       [--batch-size BATCH_SIZE]\n                       image_file [image_file ...]\n\npositional arguments:\n  image_file            input image file(s)\n\noptions:\n  -h, --help            show this help message and exit\n  --format {table,csv}  format of the output, default: csv\n  --output OUTPUT       print output to file, default: stdout\n  --rank {kingdom,phylum,class,order,family,genus,species}\n                        rank of the classification, default: species, when\n                        specified the --cls, --bins, and --subset arguments\n                        are not allowed.\n  --cls CLS             classes to predict: either a comma separated list or a\n                        path to a text file of classes (one per line), when\n                        specified the --rank, --bins, and --subset arguments\n                        are not allowed.\n  --bins BINS           path to CSV file with two columns with the first being\n                        classes and second being bin names, when specified the\n                        --rank, --cls, and --subset arguments are not allowed.\n  --subset SUBSET       path to CSV file used to subset the tree of life\n                        embeddings. CSV first column must be named one of\n                        kingdom,phylum,class,order,family,genus,species. When\n                        specified the --rank, --bins, and --cls arguments are\n                        not allowed.\n  --k K                 number of top predictions to show, default: 5\n  --device DEVICE       device to use (cpu or cuda or mps), default: cpu\n  --model MODEL         model identifier (see command list-models);\n                        default: hf-hub:imageomics/bioclip\n  --pretrained PRETRAINED\n                        pretrained model checkpoint as tag or file, depends on\n                        model; needed only if more than one is available\n                        (see command list-models)\n  --batch-size BATCH_SIZE\n                        Number of images to process in a batch, default: 10\n</code></pre></p>"},{"location":"command-line-help/#bioclip-embed","title":"bioclip embed","text":"<p>Use BioCLIP to generate embeddings for image files. <pre><code>usage: bioclip embed [-h] [--output OUTPUT] [--device DEVICE] [--model MODEL]\n                     [--pretrained PRETRAINED] image_file [image_file ...]\n\npositional arguments:\n  image_file            input image file(s)\n\noptions:\n  -h, --help            show this help message and exit\n  --output OUTPUT       print output to file, default: stdout\n  --device DEVICE       device to use (cpu or cuda or mps), default: cpu\n  --model MODEL         model identifier (see command list-models);\n                        default: hf-hub:imageomics/bioclip\n  --pretrained PRETRAINED\n                        pretrained model checkpoint as tag or file, depends\n                        on model; needed only if more than one is available\n                        (see command list-models)\n</code></pre></p>"},{"location":"command-line-help/#bioclip-list-models","title":"bioclip list-models","text":"<p>List available models and pretrained model checkpoints. <pre><code>usage: bioclip list-models [-h] [--model MODEL]\n\nNote that this will only list models known to open_clip; any model identifier\nloadable by open_clip, such as from hf-hub, file, etc should also be usable for\n--model in the embed and predict commands.\n(The default model hf-hub:imageomics/bioclip is one example.)\n\noptions:\n  -h, --help     show this help message and exit\n  --model MODEL  list available tags for pretrained model checkpoint(s) for\n                 specified model\n</code></pre></p>"},{"location":"command-line-help/#bioclip-list-tol-taxa","title":"bioclip list-tol-taxa","text":"<p>Print a CSV of the taxa embedding labels included with the tree of life model to the terminal. <pre><code>usage: bioclip list-tol-taxa [-h]\n\noptions:\n  -h, --help  show this help message and exit\n</code></pre></p>"},{"location":"command-line-tutorial/","title":"Command Line Tutorial","text":"<p>Before beginning this tutorial you need to install pybioclip and download two example images: <code>Ursus-arctos.jpeg</code> and <code>Felis-catus.jpeg</code>.</p>"},{"location":"command-line-tutorial/#tree-of-life-predictions","title":"Tree Of Life Predictions","text":"<p>The <code>bioclip predict</code> command, when not supplying a custom list of labels, will create a prediction based on the BioCLIP tree of life embeddings.</p>"},{"location":"command-line-tutorial/#predict-species-for-an-image","title":"Predict species for an image","text":"<p>Predict species for an <code>Ursus-arctos.jpeg</code> file: <pre><code>bioclip predict Ursus-arctos.jpeg\n</code></pre> Output: <pre><code>bioclip predict Ursus-arctos.jpeg\nfile_name,kingdom,phylum,class,order,family,genus,species_epithet,species,common_name,score\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctos,Ursus arctos,Kodiak bear,0.9356034994125366\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctos syriacus,Ursus arctos syriacus,syrian brown bear,0.05616999790072441\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctos bruinosus,Ursus arctos bruinosus,,0.004126196261495352\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctus,Ursus arctus,,0.0024959812872111797\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,americanus,Ursus americanus,Louisiana black bear,0.0005009894957765937\n</code></pre></p> <p>Documentation</p> <p>The bioclip predict documentation describes all arguments supported by <code>bioclip predict</code> command.</p>"},{"location":"command-line-tutorial/#predict-species-for-multiple-images-saving-to-a-file","title":"Predict species for multiple images saving to a file","text":"<p>To make predictions for files <code>Ursus-arctos.jpeg</code> and <code>Felis-catus.jpeg</code> saving the output to a file named <code>predictions.csv</code>: <pre><code>bioclip predict --output predictions.csv Ursus-arctos.jpeg Felis-catus.jpeg\n</code></pre> The contents of <code>predictions.csv</code> will look like this:  <pre><code>file_name,kingdom,phylum,class,order,family,genus,species_epithet,species,common_name,score\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctos,Ursus arctos,Kodiak bear,0.9356034994125366\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctos syriacus,Ursus arctos syriacus,syrian brown bear,0.05616999790072441\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctos bruinosus,Ursus arctos bruinosus,,0.004126196261495352\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,arctus,Ursus arctus,,0.0024959812872111797\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Carnivora,Ursidae,Ursus,americanus,Ursus americanus,Louisiana black bear,0.0005009894957765937\nFelis-catus.jpeg,Animalia,Chordata,Mammalia,Carnivora,Felidae,Felis,silvestris,Felis silvestris,European Wildcat,0.7221033573150635\nFelis-catus.jpeg,Animalia,Chordata,Mammalia,Carnivora,Felidae,Felis,catus,Felis catus,Domestic Cat,0.19810837507247925\nFelis-catus.jpeg,Animalia,Chordata,Mammalia,Carnivora,Felidae,Felis,margarita,Felis margarita,Sand Cat,0.02798456884920597\nFelis-catus.jpeg,Animalia,Chordata,Mammalia,Carnivora,Felidae,Lynx,felis,Lynx felis,,0.021829601377248764\nFelis-catus.jpeg,Animalia,Chordata,Mammalia,Carnivora,Felidae,Felis,bieti,Felis bieti,Chinese desert cat,0.010979168117046356\n</code></pre></p> <p>Documentation</p> <p>The bioclip predict documentation describes all arguments supported by <code>bioclip predict</code> command.</p>"},{"location":"command-line-tutorial/#predict-top-3-genera-for-an-image-and-display-output-as-a-table","title":"Predict top 3 genera for an image and display output as a table","text":"<pre><code>bioclip predict --format table --k 3 --rank=genus Ursus-arctos.jpeg\n</code></pre> <p>Output: <pre><code>+-------------------+----------+----------+----------+--------------+----------+--------+------------------------+\n|     file_name     | kingdom  |  phylum  |  class   |    order     |  family  | genus  |         score          |\n+-------------------+----------+----------+----------+--------------+----------+--------+------------------------+\n| Ursus-arctos.jpeg | Animalia | Chordata | Mammalia |  Carnivora   | Ursidae  | Ursus  |   0.9994320273399353   |\n| Ursus-arctos.jpeg | Animalia | Chordata | Mammalia | Artiodactyla | Cervidae | Cervus | 0.00032594642834737897 |\n| Ursus-arctos.jpeg | Animalia | Chordata | Mammalia | Artiodactyla | Cervidae | Alces  | 7.803700282238424e-05  |\n+-------------------+----------+----------+----------+--------------+----------+--------+------------------------+\n</code></pre></p> <p>Documentation</p> <p>The bioclip predict documentation describes all arguments supported by <code>bioclip predict</code> command.</p>"},{"location":"command-line-tutorial/#predict-using-a-tol-subset","title":"Predict using a TOL subset","text":"<p>The <code>predict</code> command has support for a <code>--subset &lt;csv-path&gt;</code> argument. The first column in the CSV file must be named kingdom, phylum, class, order, family, genus, or species. The values must match the TOL labels otherwise an error occurs. See the bioclip list-tol-taxa command to create a CSV of TOL labels.</p> <p>In this example we create a CSV to subset TOL to two orders. Create a CSV named <code>orders.csv</code> with the following content: <pre><code>order\nArtiodactyla\nRodentia\n</code></pre></p> <pre><code>bioclip predict --subset orders.csv Ursus-arctos.jpeg\n</code></pre> <p>Output: <pre><code>file_name,kingdom,phylum,class,order,family,genus,species_epithet,species,common_name,score\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Artiodactyla,Cervidae,Cervus,canadensis sibericus,Cervus canadensis sibericus,,0.7347981333732605\nUrsus-arctos.jpeg,Animalia,Chordata,Mammalia,Artiodactyla,Cervidae,Alces,alces,Alces alces,European elk,0.17302176356315613\n...\n</code></pre></p> <p>Documentation</p> <p>The bioclip predict documentation describes all arguments supported by <code>bioclip predict</code> command.</p>"},{"location":"command-line-tutorial/#custom-label-predictions","title":"Custom Label Predictions","text":"<p>To predict with custom labels using the <code>bioclip predict</code> command the <code>--cls</code> or <code>--bins</code> arguments must be used.</p>"},{"location":"command-line-tutorial/#predict-from-a-list-of-classes","title":"Predict from a list of classes","text":"<p>Create predictions for 3 classes (cat, bird, and bear) for image <code>Ursus-arctos.jpeg</code>: <pre><code>bioclip predict --cls cat,bird,bear Ursus-arctos.jpeg\n</code></pre> Output: <pre><code>file_name,classification,score\nUrsus-arctos.jpeg,bear,0.9999998807907104\nUrsus-arctos.jpeg,cat,4.581697155003894e-08\nUrsus-arctos.jpeg,bird,3.052039332374079e-08\n</code></pre></p> <p>Documentation</p> <p>The bioclip predict documentation describes all arguments supported by <code>bioclip predict</code> command.</p>"},{"location":"command-line-tutorial/#predict-from-a-binning-csv","title":"Predict from a binning CSV","text":"<p>Create predictions for 3 classes (cat, bird, and bear) with 2 bins (one, two) for image <code>Ursus-arctos.jpeg</code>:</p> <p>Create a CSV file named <code>bins.csv</code> with the following contents: <pre><code>cls,bin\ncat,one\nbird,one\nbear,two\n</code></pre> The names of the columns do not matter. The first column values will be used as the classes. The second column values will be used for bin names.</p> <p>Run predict command: <pre><code>bioclip predict --bins bins.csv Ursus-arctos.jpeg\n</code></pre></p> <p>Output: <pre><code>Ursus-arctos.jpeg,two,0.9999998807907104\nUrsus-arctos.jpeg,one,7.633736487377973e-08\n</code></pre></p> <p>Documentation</p> <p>The bioclip predict documentation describes all arguments supported by <code>bioclip predict</code> command.</p>"},{"location":"command-line-tutorial/#predict-using-a-custom-model","title":"Predict using a custom model","text":"<p>List available models: <pre><code>bioclip list-models\n</code></pre> Output: <pre><code>...\nViT-B-16\nViT-B-16-plus\n...\n</code></pre> List pretrained models for a model: <pre><code>bioclip list-models --model  ViT-B-16\n</code></pre> Output: <pre><code>...\nlaion2b_s34b_b88k\n...\n</code></pre> Create a prediction: <pre><code>bioclip predict --cls duck,fish,bear --model ViT-B-16 --pretrained laion2b_s34b_b88k Ursus-arctos.jpeg\n</code></pre> Output: <pre><code>file_name,classification,score\nUrsus-arctos.jpeg,bear,0.9999988079071045\nUrsus-arctos.jpeg,fish,1.1098603636128246e-06\nUrsus-arctos.jpeg,duck,2.7479762465532076e-08\n</code></pre></p>"},{"location":"command-line-tutorial/#create-embeddings","title":"Create embeddings","text":"<p>The <code>bioclip embed</code> command creates an embedding for one or more image files.</p>"},{"location":"command-line-tutorial/#create-embedding-for-an-image","title":"Create embedding for an image","text":"<p><pre><code>bioclip embed Ursus-arctos.jpeg\n</code></pre> Output: <pre><code>{\n    \"model\": \"hf-hub:imageomics/bioclip\",\n    \"embeddings\": {\n        \"Ursus-arctos.jpeg\": [\n            -0.23633578419685364,\n            -0.28467196226119995,\n            -0.4394485652446747,\n            ...\n        ]\n    }\n}\n</code></pre></p> <p>Documentation</p> <p>The bioclip embed documentation describes all arguments supported by <code>bioclip embed</code> command.</p>"},{"location":"command-line-tutorial/#view-command-line-help","title":"View command line help","text":"<pre><code>bioclip -h\nbioclip &lt;command&gt; -h\n</code></pre>"},{"location":"docker/","title":"Docker Container","text":"<p>A docker container for pybioclip is hosted at ghcr.io. This container has CPU support for Mac, Windows, and Linux. GPU(CUDA) support is only for Windows and Linux.</p>"},{"location":"docker/#volumes","title":"Volumes","text":"<p>In order to access files the docker container requires you to mount a volume. The working and home directories in this container are both set to <code>/home/bcuser</code>. Minimally you need to mount a volume into this directory so pybioclip can read your images. When running pybioclip the software will download various BioCLIP files into a <code>/home/bcuser/.cache</code> subdirectory. If you want to store the <code>.cache</code> folder in your home directory you will need to mount that directory (<code>~/.cache</code>) into the container at <code>/home/bcuser/.cache</code>.</p>"},{"location":"docker/#setup","title":"Setup","text":"<p>The examples below require an image file named Ursus-arctos.jpeg in the current directory.</p>"},{"location":"docker/#maclinux-cpu-usage","title":"Mac/Linux CPU Usage","text":"<p>The following command will create predictions for the <code>Ursus-arctos.jpeg</code> image in the current directory. The command mounts the current directory into the container at <code>/home/bcuser</code>. The command mounts the <code>~/.cache</code> directory into the container to cache BioCLIP files in your home directory. <pre><code>docker run --platform linux/amd64 \\\n           -v $(pwd):/home/bcuser \\\n           -v ~/.cache:/home/bcuser/.cache \\\n           --rm ghcr.io/imageomics/pybioclip:1.1.0 \\\n           bioclip predict Ursus-arctos.jpeg\n</code></pre></p>"},{"location":"docker/#linux-gpu-usage","title":"Linux GPU Usage","text":"<p>The following command will create predictions using a GPU for the <code>Ursus-arctos.jpeg</code> image in the current directory. <pre><code>docker run --gpus all \\\n           --platform linux/amd64 \\\n           -v $(pwd):/home/bcuser \\\n           -v ~/.cache:/home/bcuser/.cache \\\n           --rm ghcr.io/imageomics/pybioclip:1.1.0 \\\n           bioclip predict --device cuda Ursus-arctos.jpeg\n</code></pre></p>"},{"location":"docker/#windows-cpu-usage","title":"Windows CPU Usage","text":"<p>The following command will create predictions for the <code>Ursus-arctos.jpeg</code> image in the current directory. Since this command does not mount <code>/home/bcuser/.cache</code> in the container the <code>.cache</code> directory will be created within the current directory. <pre><code>docker run --rm -v %cd%:/home/bcuser ghcr.io/imageomics/pybioclip:1.0.0 bioclip predict Ursus-arctos.jpeg\n</code></pre></p>"},{"location":"docker/#windows-gpu-usage","title":"Windows GPU Usage","text":"<p>The following command will create predictions using a GPU for the <code>Ursus-arctos.jpeg</code> image in the current directory. <pre><code>docker run --rm --gpus all -v %cd%:/home/bcuser ghcr.io/imageomics/pybioclip bioclip:1.0.0 predict --device cuda Ursus-arctos.jpeg\n</code></pre></p>"},{"location":"python-api/","title":"Python API","text":"<ul> <li><code>KINGDOM</code></li> <li><code>PHYLUM</code></li> <li><code>CLASS</code></li> <li><code>ORDER</code></li> <li><code>FAMILY</code></li> <li><code>GENUS</code></li> <li><code>SPECIES</code></li> </ul>"},{"location":"python-api/#bioclip.TreeOfLifeClassifier","title":"<code>bioclip.TreeOfLifeClassifier(**kwargs)</code>","text":"<p>               Bases: <code>BaseClassifier</code></p> <p>A classifier for predicting taxonomic ranks for images.</p> <p>See <code>BaseClassifier</code> for details on <code>**kwargs</code>.</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    See `BaseClassifier` for details on `**kwargs`.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.txt_embeddings = get_txt_emb().to(self.device)\n    self.txt_names = get_txt_names()\n    self._subset_txt_embeddings = None\n    self._subset_txt_names = None\n</code></pre>"},{"location":"python-api/#bioclip.TreeOfLifeClassifier.predict","title":"<code>predict(images, rank, min_prob=1e-09, k=5, batch_size=10)</code>","text":"<p>Predicts probabilities for supplied taxa rank for given images using the Tree of Life embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>List[str] | str | List[Image]</code> <p>A list of image file paths, a single image file path, or a list of PIL Image objects.</p> required <code>rank</code> <code>Rank</code> <p>The rank at which to make predictions (e.g., species, genus).</p> required <code>min_prob</code> <code>float</code> <p>The minimum probability threshold for predictions.</p> <code>1e-09</code> <code>k</code> <code>int</code> <p>The number of top predictions to return.</p> <code>5</code> <code>batch_size</code> <code>int</code> <p>The number of images to process in a batch.</p> <code>10</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, float]]</code> <p>List[dict]: A list of dicts with keys \"file_name\", taxon ranks, \"common_name\", and \"score\".</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>@torch.no_grad()\ndef predict(self, images: List[str] | str | List[PIL.Image.Image], rank: Rank, \n            min_prob: float = 1e-9, k: int = 5, batch_size: int = 10) -&gt; dict[str, dict[str, float]]:\n    \"\"\"\n    Predicts probabilities for supplied taxa rank for given images using the Tree of Life embeddings.\n\n    Parameters:\n        images (List[str] | str | List[PIL.Image.Image]): A list of image file paths, a single image file path, or a list of PIL Image objects.\n        rank (Rank): The rank at which to make predictions (e.g., species, genus).\n        min_prob (float, optional): The minimum probability threshold for predictions.\n        k (int, optional): The number of top predictions to return.\n        batch_size (int, optional): The number of images to process in a batch.\n\n    Returns:\n        List[dict]: A list of dicts with keys \"file_name\", taxon ranks, \"common_name\", and \"score\".\n    \"\"\"\n\n    if isinstance(images, str):\n        images = [images]\n    probs = self.create_batched_probabilities_for_images(images, self.get_txt_embeddings(),\n                                                         batch_size=batch_size)\n    result = []\n    for i, image in enumerate(images):\n        key = self.make_key(image, i)\n        image_probs = probs[key].cpu()\n        if rank == Rank.SPECIES:\n            result.extend(self.format_species_probs(key, image_probs, k))\n        else:\n            result.extend(self.format_grouped_probs(key, image_probs, rank, min_prob, k))\n    return result\n</code></pre>"},{"location":"python-api/#bioclip.TreeOfLifeClassifier.get_label_data","title":"<code>get_label_data()</code>","text":"<p>Retrieves label data for the tree of life embeddings as a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing label data for TOL embeddings.</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>def get_label_data(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieves label data for the tree of life embeddings as a pandas DataFrame.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing label data for TOL embeddings.\n    \"\"\"\n\n    data = []\n    for name_ary in self.txt_names:\n        data.append(create_classification_dict(names=name_ary, rank=Rank.SPECIES))\n    return pd.DataFrame(data, copy=True)\n</code></pre>"},{"location":"python-api/#bioclip.TreeOfLifeClassifier.create_taxa_filter","title":"<code>create_taxa_filter(rank, user_values)</code>","text":"<p>Creates a filter for taxa based on the specified rank and user-provided values.</p> <p>Parameters:</p> Name Type Description Default <code>rank</code> <code>Rank</code> <p>The taxonomic rank to filter by.</p> required <code>user_values</code> <code>List[str]</code> <p>A list of user-provided values to filter the taxa.</p> required <p>Returns:</p> Type Description <code>List[bool]</code> <p>List[bool]: A list of boolean values indicating whether each entry in the          label data matches any of the user-provided values.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any of the user-provided values are not found in the label data          for the specified taxonomic rank.</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>def create_taxa_filter(self, rank: Rank, user_values: List[str]) -&gt; List[bool]:\n    \"\"\"\n    Creates a filter for taxa based on the specified rank and user-provided values.\n\n    Args:\n        rank (Rank): The taxonomic rank to filter by.\n        user_values (List[str]): A list of user-provided values to filter the taxa.\n\n    Returns:\n        List[bool]: A list of boolean values indicating whether each entry in the \n                    label data matches any of the user-provided values.\n\n    Raises:\n        ValueError: If any of the user-provided values are not found in the label data \n                    for the specified taxonomic rank.\n    \"\"\"\n\n    taxa_column = rank.get_label()\n    label_data = self.get_label_data()\n\n    # Ensure all user values exist\n    pd_user_values = pd.Series(user_values, name=taxa_column)\n    unknown_values = pd_user_values[~pd_user_values.isin(label_data[taxa_column])]\n    if not unknown_values.empty:\n        bad_species = \", \".join(unknown_values.values)\n        raise ValueError(f\"Unknown {taxa_column} received: {bad_species}. Only known {taxa_column} may be used.\")\n\n    return label_data[taxa_column].isin(pd_user_values)\n</code></pre>"},{"location":"python-api/#bioclip.TreeOfLifeClassifier.apply_filter","title":"<code>apply_filter(keep_labels_ary)</code>","text":"<p>Filters the TOL embeddings based on the provided boolean array. See <code>create_taxa_filter()</code> for an easy way to create this parameter.</p> <p>Parameters:</p> Name Type Description Default <code>keep_labels_ary</code> <code>List[bool]</code> <p>A list of boolean values indicating which                            TOL embeddings to keep.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the length of keep_labels_ary does not match the expected length.</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>def apply_filter(self, keep_labels_ary: List[bool]):\n    \"\"\"\n    Filters the TOL embeddings based on the provided boolean array. See `create_taxa_filter()` for an easy way to create this parameter.\n\n    Args:\n        keep_labels_ary (List[bool]): A list of boolean values indicating which \n                                      TOL embeddings to keep.\n\n    Raises:\n        ValueError: If the length of keep_labels_ary does not match the expected length.\n    \"\"\"\n\n    if len(keep_labels_ary) != len(self.txt_names):\n        expected = len(self.txt_names)\n        raise ValueError(\"Invalid keep_embeddings values. \" + \n                         f\"This parameter should be a list containing {expected} items.\")\n    embeddings = []\n    names = []\n    for idx, keep in enumerate(keep_labels_ary):\n        if keep:\n            embeddings.append(self.txt_embeddings[:,idx])\n            names.append(self.txt_names[idx])\n    self._subset_txt_embeddings = torch.stack(embeddings, dim=1)\n    self._subset_txt_names = names\n</code></pre>"},{"location":"python-api/#bioclip.Rank","title":"<code>bioclip.Rank</code>","text":"<p>Rank for the Tree of Life classification.</p>"},{"location":"python-api/#bioclip.CustomLabelsClassifier","title":"<code>bioclip.CustomLabelsClassifier(cls_ary, **kwargs)</code>","text":"<p>               Bases: <code>BaseClassifier</code></p> <p>A classifier that predicts from a list of custom labels for images.</p> <p>Initializes the classifier with the given class array and additional keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>cls_ary</code> <code>List[str]</code> <p>A list of class names as strings.</p> required Source code in <code>src/bioclip/predict.py</code> <pre><code>def __init__(self, cls_ary: List[str], **kwargs):\n    \"\"\"\n    Initializes the classifier with the given class array and additional keyword arguments.\n\n    Parameters:\n        cls_ary (List[str]): A list of class names as strings.\n    \"\"\"\n    super().__init__(**kwargs)\n    self.tokenizer = create_bioclip_tokenizer(self.model_str)\n    self.classes = [cls.strip() for cls in cls_ary]\n    self.txt_embeddings = self._get_txt_embeddings(self.classes)\n</code></pre>"},{"location":"python-api/#bioclip.CustomLabelsClassifier.predict","title":"<code>predict(images, k=None, batch_size=10)</code>","text":"<p>Predicts the probabilities for the given images.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>List[str] | str | List[Image]</code> <p>A list of image file paths, a single image file path, or a list of PIL Image objects.</p> required <code>k</code> <code>int</code> <p>The number of top probabilities to return. If not specified or if greater than the number of classes, all probabilities are returned.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>The number of images to process in a batch.</p> <code>10</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>List[dict]: A list of dicts with keys \"file_name\" and the custom class labels.</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>@torch.no_grad()\ndef predict(self, images: List[str] | str | List[PIL.Image.Image], k: int = None,\n            batch_size: int = 10) -&gt; dict[str, float]:\n    \"\"\"\n    Predicts the probabilities for the given images.\n\n    Parameters:\n        images (List[str] | str | List[PIL.Image.Image]): A list of image file paths, a single image file path, or a list of PIL Image objects.\n        k (int, optional): The number of top probabilities to return. If not specified or if greater than the number of classes, all probabilities are returned.\n        batch_size (int, optional): The number of images to process in a batch.\n\n    Returns:\n        List[dict]: A list of dicts with keys \"file_name\" and the custom class labels.\n    \"\"\"\n    if isinstance(images, str):\n        images = [images]\n    probs = self.create_batched_probabilities_for_images(images, self.txt_embeddings,\n                                                         batch_size=batch_size)\n    result = []\n    for i, image in enumerate(images):\n        key = self.make_key(image, i)\n        img_probs = probs[key]\n        if not k or k &gt; len(self.classes):\n            k = len(self.classes)\n        result.extend(self.group_probs(key, img_probs, k))\n    return result\n</code></pre>"},{"location":"python-api/#bioclip.CustomLabelsBinningClassifier","title":"<code>bioclip.CustomLabelsBinningClassifier(cls_to_bin, **kwargs)</code>","text":"<p>               Bases: <code>CustomLabelsClassifier</code></p> <p>A classifier that creates predictions for images based on custom labels, groups the labels, and calculates probabilities for each group.</p> <p>Initializes the class with a dictionary mapping class labels to binary values.</p> <p>Parameters:</p> Name Type Description Default <code>cls_to_bin</code> <code>dict</code> <p>A dictionary where keys are class labels and values are binary values.</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to the superclass initializer.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any value in <code>cls_to_bin</code> is empty, null, or NaN.</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>def __init__(self, cls_to_bin: dict, **kwargs):\n    \"\"\"\n    Initializes the class with a dictionary mapping class labels to binary values.\n\n    Args:\n        cls_to_bin (dict): A dictionary where keys are class labels and values are binary values.\n        **kwargs: Additional keyword arguments passed to the superclass initializer.\n\n    Raises:\n        ValueError: If any value in `cls_to_bin` is empty, null, or NaN.\n    \"\"\"\n    super().__init__(cls_ary=cls_to_bin.keys(), **kwargs)\n    self.cls_to_bin = cls_to_bin\n    if any([pd.isna(x) or not x for x in cls_to_bin.values()]):\n        raise ValueError(\"Empty, null, or nan are not allowed for bin values.\")\n</code></pre>"},{"location":"python-api/#bioclip.predict.BaseClassifier","title":"<code>bioclip.predict.BaseClassifier(model_str=BIOCLIP_MODEL_STR, pretrained_str=None, device='cpu')</code>","text":"<p>               Bases: <code>Module</code></p> <p>Initializes the prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>model_str</code> <code>str</code> <p>The string identifier for the model to be used.</p> <code>BIOCLIP_MODEL_STR</code> <code>pretrained_str</code> <code>str</code> <p>The string identifier for the pretrained model to be loaded.</p> <code>None</code> <code>device</code> <code>Union[str, device]</code> <p>The device on which the model will be run.</p> <code>'cpu'</code> Source code in <code>src/bioclip/predict.py</code> <pre><code>def __init__(self, model_str: str = BIOCLIP_MODEL_STR, pretrained_str: str | None = None, device: Union[str, torch.device] = 'cpu'):\n    \"\"\"\n    Initializes the prediction model.\n\n    Parameters:\n        model_str (str): The string identifier for the model to be used.\n        pretrained_str (str, optional): The string identifier for the pretrained model to be loaded.\n        device (Union[str, torch.device]): The device on which the model will be run.\n    \"\"\"\n    super().__init__()\n    self.device = device\n    self.load_pretrained_model(model_str=model_str, pretrained_str=pretrained_str)\n</code></pre>"},{"location":"python-api/#bioclip.predict.BaseClassifier.forward","title":"<code>forward(x)</code>","text":"<p>Given an input tensor representing multiple images, return probabilities for each class for each image. Args:     x (torch.Tensor): Input tensor representing the multiple images. Returns:     torch.Tensor: Softmax probabilities of the logits for each class for each image.</p> Source code in <code>src/bioclip/predict.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Given an input tensor representing multiple images, return probabilities for each class for each image.\n    Args:\n        x (torch.Tensor): Input tensor representing the multiple images.\n    Returns:\n        torch.Tensor: Softmax probabilities of the logits for each class for each image.\n    \"\"\"\n    img_features = self.model.encode_image(x)\n    img_features = F.normalize(img_features, dim=-1)\n    return self.create_probabilities(img_features, self.txt_embeddings)\n</code></pre>"},{"location":"python-tutorial/","title":"Python Tutorial","text":"<p>Before beginning this tutorial you need to install pybioclip and download two example images: <code>Ursus-arctos.jpeg</code>  and <code>Felis-catus.jpeg</code>.</p>"},{"location":"python-tutorial/#predict-species-classification","title":"Predict species classification","text":"<pre><code>from bioclip import TreeOfLifeClassifier, Rank\n\nclassifier = TreeOfLifeClassifier()\npredictions = classifier.predict(\"Ursus-arctos.jpeg\", Rank.SPECIES)\n\nfor prediction in predictions:\n    print(prediction[\"species\"], \"-\", prediction[\"score\"])\n</code></pre> <p>Output: <pre><code>Ursus arctos - 0.9356034994125366\nUrsus arctos syriacus - 0.05616999790072441\nUrsus arctos bruinosus - 0.004126196261495352\nUrsus arctus - 0.0024959812872111797\nUrsus americanus - 0.0005009894957765937\n</code></pre></p> <p>Output from the <code>predict()</code> method showing the dictionary structure: <pre><code>[{\n    'kingdom': 'Animalia',\n    'phylum': 'Chordata',\n    'class': 'Mammalia',\n    'order': 'Carnivora',\n    'family': 'Ursidae',\n    'genus': 'Ursus',\n    'species_epithet': 'arctos',\n    'species': 'Ursus arctos',\n    'common_name': 'Kodiak bear'\n    'score': 0.9356034994125366\n}]\n</code></pre></p> <p>The output from the predict function can be converted into a pandas DataFrame like so: <pre><code>import pandas as pd\nfrom bioclip import TreeOfLifeClassifier, Rank\n\nclassifier = TreeOfLifeClassifier()\npredictions = classifier.predict(\"Ursus-arctos.jpeg\", Rank.SPECIES)\ndf = pd.DataFrame(predictions)\n</code></pre></p> <p>The first argument of the <code>predict()</code> method supports both a single path or a list of paths.</p> <p>Documentation</p> <p>The TreeOfLifeClassifier docs contains details about the arguments supported by the constructor and the <code>predict()</code> method.</p>"},{"location":"python-tutorial/#predict-from-a-list-of-classes","title":"Predict from a list of classes","text":"<p><pre><code>from bioclip import CustomLabelsClassifier\n\nclassifier = CustomLabelsClassifier([\"duck\",\"fish\",\"bear\"])\npredictions = classifier.predict(\"Ursus-arctos.jpeg\")\nfor prediction in predictions:\n   print(prediction[\"classification\"], prediction[\"score\"])\n</code></pre> Output: <pre><code>duck 1.0306726583309e-09\nfish 2.932403668845507e-12\nbear 1.0\n</code></pre></p> <p>Documentation</p> <p>The CustomLabelsClassifier docs contains details about the arguments supported by the constructor and the <code>predict()</code> method.</p>"},{"location":"python-tutorial/#predict-using-a-custom-model","title":"Predict using a Custom Model","text":"<p>To predict with a custom model the <code>model_str</code> and <code>pretrained_str</code> arguments must be specified. In this example the CLIP-ViT-B-16-laion2B-s34B-b88K model is used. <pre><code>from bioclip import CustomLabelsClassifier\n\nclassifier = CustomLabelsClassifier(\n    cls_ary = [\"duck\",\"fish\",\"bear\"],\n    model_str='ViT-B-16',\n    pretrained_str='laion2b_s34b_b88k')\n\nprint(classifier.predict(\"Ursus-arctos.jpeg\"))\n</code></pre></p> <p>See this tutorial for instructions for listing available pretrained models.</p>"},{"location":"python-tutorial/#predict-from-a-list-of-classes-with-binning","title":"Predict from a list of classes with binning","text":"<p><pre><code>from bioclip import CustomLabelsBinningClassifier\n\nclassifier = CustomLabelsBinningClassifier(cls_to_bin={\n  'dog': 'small',\n  'fish': 'small',\n  'bear': 'big',\n})\npredictions = classifier.predict(\"Ursus-arctos.jpeg\")\n\nfor prediction in predictions:\n   print(prediction[\"classification\"], prediction[\"score\"])\n</code></pre> Output: <pre><code>big 0.99992835521698\nsmall 7.165559509303421e-05\n</code></pre></p> <p>Documentation</p> <p>The CustomLabelsBinningClassifier documentation describes all arguments supported by the constructor. The base class CustomLabelsClassifier docs describes arguments for the predict method.</p>"},{"location":"python-tutorial/#example-notebooks","title":"Example Notebooks","text":""},{"location":"python-tutorial/#predict-species-for-images","title":"Predict species for images","text":"<p>PredictImages.ipynb  downloads some images and predicts species. </p>"},{"location":"python-tutorial/#predict-species-for-inaturalist-images","title":"Predict species for iNaturalist images","text":"<p>iNaturalistPredict.ipynb downloads images from inaturalist.org and predicts species.  </p>"},{"location":"python-tutorial/#predict-using-a-subset-of-the-treeoflife","title":"Predict using a subset of the TreeOfLife","text":"<p>TOL-Subsetting.ipynb filters the TreeOfLife embeddings.  </p> <p>Documentation</p> <p>For subsetting the TreeOfLifeClassifier see get_label_data(), create_taxa_filter() and apply_filter() .</p>"},{"location":"python-tutorial/#experiment-with-grad-cam","title":"Experiment with grad-cam","text":"<p>GradCamExperiment.ipynb  applies GradCAM AI explainability to BioCLIP.  </p>"},{"location":"python-tutorial/#fine-tune","title":"Fine-tune","text":"<p>The following notebooks show methods to fine-tune BioCLIP for classification.</p> <ul> <li> <p>FineTuneSVM.ipynb fine-tunes  BioCLIP by combining an SVM with BioCLIP image embeddings.  </p> </li> <li> <p>FineTuneRidgeClassifier.ipynb fine-tunes BioCLIP by combining a RidgeClassifier with BioCLIP image embeddings.  </p> </li> </ul> <p>As can be seen from comparing the confusion matrices in the notebooks, fine-tuning may yield better results than using BioCLIP in \"zero-shot mode\", i.e., predicting on a list of custom labels.</p> <p>This work is based on code from biobench.</p>"},{"location":"python-tutorial/#pil-images","title":"PIL Images","text":"<p>The predict() functions used in all the examples above allow passing a list of paths or a list of PIL Images. When a list of PIL images is passed the index of the image will be filled in for <code>file_name</code>. This is because PIL images may not have an associated file name.</p>"}]}